{
 "metadata": {
  "name": "",
  "signature": "sha256:f1d73febea6f01faae8f1877898723a015e7e61ec5c499b6a3e6dfe2a0b10e0d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Step 1: Reading Data\n",
      "\n",
      "These headers are written in Markdown language.  It's just a cover for HTML.  Go here for more info https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "The first few imported libraries here should\n",
      "be included with Anaconda- so you should just run them.\n",
      "If I'm mistaken in that, then you simply need \n",
      "to type \"conda install numpy\" and \"conda install matplotlib\"\n",
      "into your shell and say yes to the prompts- but try running\n",
      "this cell first.\n",
      "'''\n",
      "import sys #for some clean print statements"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Reading a local file with open & csvreader\n",
      "Docs here https://docs.python.org/2/library/csv.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv #readers and writers for comma separated values files\n",
      "\n",
      "dropout_data_by_field = dict()\n",
      "dropout_data_by_state = dict()\n",
      "'''\n",
      "Reading a file with open & a csvreader \n",
      "(csvreader is not necessarily if it just a text file).\n",
      "In this case this is the hard way- the second\n",
      "example will be way easier.  But you still\n",
      "have to be able to read data the traditional way\n",
      "for many circumstances.  And understanding\n",
      "how to work with dictionaries is a must.\n",
      "'''\n",
      "with open('..\\..\\..\\data\\dropout-rates.csv') as csvfile:\n",
      "    readr = csv.reader(csvfile)\n",
      "    \n",
      "    #This data file has 6 header lines with no data in them\n",
      "    for i in range(6):\n",
      "        next(readr)\n",
      "    \n",
      "    #This row contains the field labels in it\n",
      "    labels = next(readr)\n",
      "    \n",
      "    #Have to initialize  dictionary set with an empy list and a key\n",
      "    for l in labels:\n",
      "        dropout_data_by_field[l] = []\n",
      "    \n",
      "    for row in readr:\n",
      "        state = row[0]\n",
      "        \n",
      "        if state:\n",
      "            dropout_data_by_state[state] = []\n",
      "            dropout_data_by_field[labels[0]].append(state)\n",
      "            \n",
      "            for i in range(1,len(row)):\n",
      "                #Some data fields have missing values\n",
      "                try:\n",
      "                    val = float(row[i])\n",
      "                except:\n",
      "                    val = 'missing'\n",
      "                    \n",
      "                dropout_data_by_state[state].append(val)\n",
      "                dropout_data_by_field[labels[i]].append(val)\n",
      "        else:\n",
      "            break\n",
      "\n",
      "#Now we can print each data field by state:\n",
      "state = 'COLORADO'\n",
      "print state,'\\n',\n",
      "\n",
      "for i in range(7):\n",
      "    print labels[i+1],'\\n',dropout_data_by_state[state][i]\n",
      "                                            \n",
      "#And by fields\n",
      "field = labels[4]\n",
      "\n",
      "state_label = labels[0]\n",
      "print '\\n',state_label,'\\t\\t\\t\\t',field,'\\n'\n",
      "\n",
      "#This is some ugly manipulation to print cleanly\n",
      "for i in range(len(dropout_data_by_field[state_label])):\n",
      "    state = dropout_data_by_field[state_label][i]\n",
      "    \n",
      "    sys.stdout.write(state)\n",
      "    \n",
      "    for t in range(int(5 - len(state)/8)):\n",
      "        sys.stdout.write('\\t')\n",
      "    \n",
      "    sys.stdout.write(str(dropout_data_by_field[field][i])+'\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Reading a local file with numpy\n",
      "Docs here http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np #library for working with arrays & matrices of data\n",
      "\n",
      "'''\n",
      "Using numpy.  In this case this is the easy way For sure!\n",
      "'''\n",
      "\n",
      "#These provide labels & data types as tuples\n",
      "col_dtypes = [('state','S32'),\n",
      "              ('NAM',float),\n",
      "              ('ASI',float),\n",
      "              ('BLK',float),\n",
      "              ('HIS',float),\n",
      "              ('WHT',float),\n",
      "              ('HAW',float),\n",
      "              ('MUL',float)]\n",
      "\n",
      "#One line!\n",
      "dropout_data = np.genfromtxt('..\\..\\..\\data\\dropout-rates.csv',delimiter=',',dtype=col_dtypes,skip_header=7)   \n",
      "\n",
      "#now we can print the columns like we had in dropout_data_by_field below:\n",
      "print dropout_data['HIS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Reading a text file off the web\n",
      "\n",
      "Heres a link to python's built-in function docs https://docs.python.org/2/library/functions.html\n",
      "<br>And to urllib specifically https://docs.python.org/2/library/urllib.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib #Library for reading data from specified locations\n",
      "from StringIO import StringIO #Converts data string to numbers\n",
      "\n",
      "#If you don't know already '\\' continues a line in python.\n",
      "\n",
      "#Opening urls to text files containing Colorado's monthly climate data from 2014\n",
      "headers = urllib \\\n",
      ".urlopen('http://www1.ncdc.noaa.gov/pub/data/uscrn/products/monthly01/HEADERS.txt').read()\n",
      "data = urllib \\\n",
      ".urlopen('http://www1.ncdc.noaa.gov/pub/data/uscrn/products/monthly01/CRNM0102-CO_Boulder_14_W.txt').read()\n",
      "\n",
      "data = StringIO(data)\n",
      "\n",
      "#String parsing to get the headers out of the header file (it contains extra info)\n",
      "header_list = []\n",
      "header_letters = [h for h in headers.replace(' ',',') if not unicode(h).isnumeric()]\n",
      "header = ''\n",
      "\n",
      "for l in header_letters:\n",
      "    if l == ',':\n",
      "        if header:\n",
      "            header_list.append(header)\n",
      "            header = ''\n",
      "        continue\n",
      "    header += l\n",
      "\n",
      "#This particular header file contains units too if we want them\n",
      "units = header_list[15:29]\n",
      "header_list = header_list[0:14]\n",
      "\n",
      "#Using genfromtxt again\n",
      "climate_data = np.genfromtxt(data,names=header_list)\n",
      "\n",
      "#Here's a look at the monthly maximum air temperature at some wonky location\n",
      "print climate_data['T_MONTHLY_MAX']\n",
      "\n",
      "#NOTE that missing values in this dataset are down as -9999.  No world-ending temps."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Reading HTML off the web\n",
      "\n",
      "Docs for BeautifulSoup http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "<br>Page we're parsing http://www.bls.gov/cps/cpsaat39.htm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###...But first, installing libraries.\n",
      "\n",
      "In order to run the import statement below you'll need BeautifulSoup installed.  Run \"conda install beautiful-soup\" in your command prompt.  It should say its fetching it, and then prompt you with a yes or no continue prompt.  Say yes, and you'll have it installed.  You will need to restart your notebook server before it will work.  So just use ctrl-c at the command prompt to end the server and reenter \"ipython notebook\", then come and refresh this page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup as soup #This library allows you to parse HTML easily"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you got that working, then the next thing you want to do is read HTML.  If you aren't familiar with the plug-in \"Firebug\" in Firefox, or just using the native HTML inspectors in Chrome and Safari, then you should learn (and if you use IE, stop).  You can right click any web page and select \"inspect element\" and it will open up the page's source code.  If you go the link of the bls.gov page above you can see it has an embedded table.  If you open the source you'll see there's a table tag with table header tags and table row tags and much more inside.  By looking at this I was able to write a parser for it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read in a url again\n",
      "url_data = urllib.urlopen('http://www.bls.gov/cps/cpsaat39.htm')\n",
      "\n",
      "#Set up to read rows and columns again like in the first example\n",
      "data_by_field = dict()\n",
      "data_by_occ = dict()\n",
      "\n",
      "#Reading the headers in a meaningful way is a little annoying on this page, so I just wrote them in\n",
      "header_list = ['Occupation','Total Number Of Workers','Total Median Weekly Earnings',\n",
      "               'Men Number Of Workers','Men Median Weekly Earnings',\n",
      "               'Women Number Of Workers','Women Median Weekly Earnings']\n",
      "occ_list = []\n",
      "\n",
      "#Initialize the headers in the fields list\n",
      "for h in header_list:\n",
      "    data_by_field[h] = []\n",
      "    \n",
      "#Create a 'soup' object for reading the page's HTML\n",
      "html_parser = soup(url_data)\n",
      "\n",
      "#Find the table in the HTML by looking for the tag 'tbody' for table body\n",
      "table = html_parser.find('tbody')\n",
      "\n",
      "#Iterate across each instance of the table row (tr) tag\n",
      "for row in table.find_all('tr'):\n",
      "    #Find each header's text in the table header (th) tag and its corresponding text (p) tag\n",
      "    header = row.find(['th','p'])\n",
      "    \n",
      "    #Set the header in our lists if it's there\n",
      "    if header:\n",
      "        data_by_field[header_list[0]].append(header.string)\n",
      "        data_by_occ[header.string] = []\n",
      "        occ_list.append(header.string)\n",
      "        \n",
      "    #Grab the data by recognizing the class 'datavlue'\n",
      "    h = 1\n",
      "    for val in row.find_all(class_='datavalue'):\n",
      "        data_str = ''.join([c for c in val.string if unicode(c).isnumeric()])\n",
      "        \n",
      "        if data_str:\n",
      "            entry = int(data_str)\n",
      "        else:\n",
      "            entry = 'missing'\n",
      "            \n",
      "        data_by_field[header_list[h]].append(entry)\n",
      "        data_by_occ[header.string].append(entry)\n",
      "            \n",
      "        h += 1\n",
      "\n",
      "#Like in our first example I've read the data such that it can be queried by rows or columns:\n",
      "\n",
      "#Printing by a selected occupation:\n",
      "occupation = occ_list[6]\n",
      "\n",
      "print occupation,'\\n'\n",
      "\n",
      "for i in range(6):\n",
      "    print header_list[i+1],'\\n',data_by_occ[occupation][i]\n",
      "\n",
      "#Printing by a column field like women's weekly earnings:\n",
      "field = header_list[6]\n",
      "data_by_field[field]\n",
      "occ_label = header_list[0]\n",
      "\n",
      "print '\\n',occ_label,'\\t\\t\\t\\t\\t',field,'\\n'\n",
      "\n",
      "#More ugly string manipulation\n",
      "for i in range(len(occ_list)):\n",
      "    occ = occ_list[i]\n",
      "    \n",
      "    sys.stdout.write(occ[0:40])\n",
      "    \n",
      "    for t in range(int(6 - len(occ[0:40])/8)):\n",
      "        sys.stdout.write('\\t')\n",
      "    \n",
      "    sys.stdout.write(str(data_by_field[field][i])+'\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Step 2: Computing Statistics\n",
      "Docs here http://docs.scipy.org/doc/scipy/reference/stats.html\n",
      "\n",
      "If you are so inclined here's a link to scipy's statistics package.  Just showing the concept here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import stats\n",
      "\n",
      "#numpy has your basic friendly stats functions\n",
      "\n",
      "#with a little dataset\n",
      "print np.mean([1,2,3,4])\n",
      "\n",
      "#And on one of our examples, here the average weekly earnings of a woman across all industries\n",
      "print np.mean([x for x in data_by_field[header_list[6]] if unicode(x).isnumeric()])\n",
      "\n",
      "#The weird statement above to just to remove the 'missing' strings from the average calculation\n",
      "\n",
      "#And here's a linear regression of black and white dropout rates by state\n",
      "his_matches = []\n",
      "wht_matches = []\n",
      "\n",
      "#First have to fold out any data where both numbers aren't available for the state\n",
      "for i in range(len(dropout_data_by_field[labels[4]])):\n",
      "    his_val = dropout_data_by_field[labels[4]][i]\n",
      "    wht_val = dropout_data_by_field[labels[5]][i]\n",
      "    \n",
      "    if not unicode(his_val).isalpha() and not unicode(wht_val).isalpha():\n",
      "        his_matches.append(his_val)\n",
      "        wht_matches.append(wht_val)\n",
      "\n",
      "slope, intercept, r_value, p_value, std_err = stats.linregress(his_matches,wht_matches)\n",
      "\n",
      "'''\n",
      "Regression coefficient (measurement of linear relationship from -1 -> 1\n",
      "where -1 is perfectly negatively correlated, 1 is perfectly positive,\n",
      "and 0 is completely unrelated.\n",
      "'''\n",
      "print r_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Step 3: Plotting Data\n",
      "\n",
      "Docs here http://matplotlib.org/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt #Matlab's plotting functions, basically\n",
      "\n",
      "#I'll just do a quick example of women's wages vs. men's wages across occupations\n",
      "\n",
      "m_matches = []\n",
      "w_matches = []\n",
      "\n",
      "#Same little process to only have matches, with no 'missings' in there\n",
      "for i in range(len(data_by_field[header_list[6]])):\n",
      "    m_val = data_by_field[header_list[4]][i]\n",
      "    w_val = data_by_field[header_list[6]][i]\n",
      "    \n",
      "    if not unicode(m_val).isalpha() and not unicode(w_val).isalpha():\n",
      "        m_matches.append(m_val)\n",
      "        w_matches.append(w_val)\n",
      "\n",
      "#Create scater plot\n",
      "plt.scatter(m_matches,w_matches)\n",
      "\n",
      "#Labels\n",
      "plt.xlabel(\"Men's weekly earnings in $\")\n",
      "plt.ylabel(\"Women's weekly earnings in $\")\n",
      "plt.title(\"Women's wages vs. Men's wages across Occupation\")\n",
      "\n",
      "'''\n",
      "Here's a little bit to throw a line showing 'if all were equal'.\n",
      "Pts above the line indicate wage in favor of women, below in favor of men.\n",
      "'''\n",
      "pts = np.linspace(0,2500,2500)\n",
      "plt.plot(pts,pts,linewidth=2,color='r')\n",
      "\n",
      "#A window will pop up with the plot!\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}